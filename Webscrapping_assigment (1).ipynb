{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139cd318-4974-4e5c-be94-b5f0070a57ff",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada3dcf-76d5-4e2d-a06e-2a2a2678ac49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "`Web scraping` is a technique used to extract data from websites. It's like having a digital robot that visits web pages, reads the information displayed on those pages, and collects specific data of interest. This data can be anything from product prices and reviews to news articles or weather forecasts.\n",
    "\n",
    "`why it use for`: \n",
    "1. Data collection: Gathering structured data from websites for various purposes.\n",
    "2. Research and analysis: Extracting data from online sources to gain insights and support decision-making.\n",
    "3. Aggregation and integration: Combining data from multiple websites or platforms into a single database or application.\n",
    "4. Automation: Automating repetitive tasks of extracting data, saving time and effort.\n",
    "5. Monitoring and tracking: Keeping track of changes on websites for monitoring purposes.\n",
    "\n",
    "`Area in which it is use`:\n",
    "1. E-commerce: Price comparison, product information extraction, and monitoring competitor pricing and product catalogs.\n",
    "2. E-commerce: Price comparison, product information extraction, and monitoring competitor pricing and product catalogs.\n",
    "3. Financial Services: Collecting financial data, stock market information, and monitoring news related to investments.\n",
    "4. Real Estate: Extracting property listings, rental prices, and market data for analysis and comparison.\n",
    "5. Social Media Analysis: Scraping social media platforms for sentiment analysis, monitoring brand mentions, and tracking social media trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe041f00-0e30-4dfb-8dda-1d5433d838a0",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2e38d7-c9fb-42d2-a9bf-88106fe9d8c8",
   "metadata": {},
   "source": [
    "* `Manual scraping`: This method involves manually copying and pasting data from web pages into a local file or application. It is a basic and time-consuming approach, suitable for small-scale scraping tasks.\n",
    "\n",
    "* `Parsing HTML`: Parsing HTML using libraries or frameworks allows for structured extraction of data. Tools like BeautifulSoup (Python), JSoup (Java), and Nokogiri (Ruby) enable navigating the HTML structure and extracting desired information.\n",
    "\n",
    "* `Web scraping framework`s: Frameworks like bs4(BeautifulSoup) and scrapy (Python), Puppeteer (Node.js), and Selenium (multiple languages) provide higher-level abstractions and tools for web scraping. They handle various tasks such as handling cookies, sessions, form submissions, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735427e-a4f0-4ea1-afdf-8d30af6d367c",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe540ba-08c1-46d1-972b-7d525ab6ae05",
   "metadata": {},
   "source": [
    "`BeautifulSoup` is a Python library used for web scraping. It provides tools and methods for parsing HTML and XML documents, allowing users to extract data from web pages easily. BeautifulSoup helps in navigating the HTML structure, searching for specific elements, and extracting desired information efficiently.\n",
    "\n",
    "`Reason to use bs4`:\n",
    "1. bs4 excels at parsing and understanding HTML and XML documents.\n",
    "2. It has an easy-to-use and intuitive API, making it beginner-friendly.\n",
    "3. BeautifulSoup provides powerful searching and filtering methods to locate specific elements within HTML documents.\n",
    "4. It offers functionality to extract data from HTML elements, such as text, attributes, and nested elements.\n",
    "5. It can handle imperfect or poorly formatted HTML gracefully.\n",
    "6. BeautifulSoup is compatible with various versions of Python and supports both HTML and XML parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4803e8-cfcb-4798-8e62-0ae40f88137c",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bafdf3-0d6c-4df9-913e-a65ef7386ddd",
   "metadata": {},
   "source": [
    "`Flask is uesd for web scrapping to  :`\n",
    "\n",
    "* Web Application Development: Flask is a web framework used for developing web applications.\n",
    "\n",
    "* Routing: Flask allows you to define routes, which determine how URLs are handled in the application.\n",
    "\n",
    "* HTML Template Rendering: Flask's render_template function is used to render HTML templates, allowing the dynamic generation of web pages.\n",
    "\n",
    "* Handling HTTP Requests: Flask handles HTTP requests from clients and provides functionality to process different types of requests, such as GET and POST.\n",
    "\n",
    "* In summary, Flask is used for web application development, handling routing and HTTP requests, rendering HTML templates, integrating web scraping, and providing a web server for running the application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7d4f22-a006-43d0-b3c5-26ff368843de",
   "metadata": {},
   "source": [
    "### Q5.Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ebe25a-adea-4cab-94ab-63b507cab115",
   "metadata": {},
   "source": [
    "AWS CodePipeline:\n",
    "AWS CodePipeline is a fully managed continuous integration and continuous delivery (CI/CD) service. It helps you automate and streamline the process of building, testing, and deploying applications. CodePipeline allows you to define a series of stages and actions that enable the automated release of software changes.\n",
    "\n",
    "AWS Elastic Beanstalk:\n",
    "AWS Elastic Beanstalk is a fully managed platform-as-a-service (PaaS) offering that simplifies the deployment and management of applications. It abstracts away the underlying infrastructure details, allowing you to focus on application development rather than infrastructure configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d70b6e-93bb-4c1e-a798-5dc70932e203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
